\chapter{Future Work}
\label{sec:future_work}

In this chapter, we discuss some of the possible improvements that could be made to the current system to improve its performance and usability.

\section{Dynamic Rule Generation}

The current rule extraction process is static and requires a pre-collected dataset of selected scenarios. This is an obvious limitation, as users cannot be expected to collect a dataset of scenarios prior to using the library. Another issue is that the generated rules can only be expected to perform well in scenarios similar to the ones in the dataset, preventing the rules from being shared between vastly different use cases.

One could look into ways of adaptively updating the expert knowledge as new scenarios are encountered. This could be done by spending extra time during the simulation to evaluate the performance data of recently or additionally executed configurations and update the expert knowledge accordingly by retraining the underlying Decision Trees on the fly.

\section{Improving Tuning Strategies}

As previously discussed in \autoref{sec:earlyStopping}, all current tuning strategies suffer from evaluating extremely bad configurations during the tuning phases. Especially for strategies without rule-based selection, this is a significant issue and causes enormous tuning overhead that could be avoided. Implementing an early stopping mechanism could drastically improve all tuning strategies and thus benefit the core idea of AutoPas.

\section{Simplification of the Fuzzy System to Decision Trees}

As the current way of generating the Fuzzy Systems with the data-driven approach already makes use of Decision Trees, one could look into ways of directly using the Decision Trees to make decisions.

The currently used implementation of the Component Tuning approach, already is quite close to a Decision Tree approach as it used the MOM defuzzification. Since this aproach showed good results, it is possible that the Fuzzy Tuning approach could be simplified to a Decision Tree approach without losing much performance. This would make the tuning process more transparent and easier to understand for users, as the complexity intrpduced by fuzzy sets and membership functions could be avoided.

To test this hypothesis using the current system, one could change membership functions to crisp splits as originally depicted in \autoref{fig:fuzzyMembershipFunctions} and rerun the benchmarks to see if the performance is still comparable. Such a rule file would emulate (Crisp) Decision Trees, following the same rules but without the fuzziness.