\chapter{Future Work}
\label{sec:future_work}

In this chapter, we discuss some of the possible improvements that could be made to the current system to improve its performance and usability.

\section{Dynamic Rule Generation}

The current rule extraction process is static and requires a pre-collected dataset of selected scenarios. This is an obvious limitation, as users cannot be expected to collect a dataset of scenarios prior to using the library. Another issue is that the generated rules will only generalize well to scenarios similar to the ones in the dataset, preventing the rules from being shared between different use cases.

One could look into ways of adaptively updating the expert knowledge as new scenarios are encountered. This could be done by spending extra time during the simulation to evaluate the performance data of recently executed configurations and update the expert knowledge accordingly.

\section{Future Work on Tuning Strategies}

The executed benchmarks showed that all classical tuning strategies suffer from bad configurations that are evaluated during the tuning phases, which causes a significant increase in total simulation time. To solve this issue, one could look into ways of prematurely aborting evaluations of configurations that are unlikely to be selected as the best configuration.

One could just keep track of the configuration used in the previous simulation phase and reject any configuration that does not significantly improve the performance.
Such a system would drastically improve every existing tuning strategy and could drastically improve the library's performance.

\section{Simplification of the Fuzzy System to Decision Trees}

As the current way of generating the Fuzzy Systems with the data-driven approach already makes use of Decision Trees, one could look into ways of directly using the Decision Trees to make decisions.
As the Component Tuning approach doesn't make use of the power of defuzzification, it is possible that the Fuzzy Tuning approach could be simplified to a Decision Tree approach without losing any performance.

To test this hypothesis, one could change membership functions to crisp splits as originally depicted in \autoref{fig:fuzzyMembershipFunctions} and rerun the benchmarks to see if the performance is still comparable. This essentially emulates (Crisp) Decision Trees trained from the same dataset.