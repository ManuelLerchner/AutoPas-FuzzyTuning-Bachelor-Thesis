Comments can be made just like this
Best thesis ever:
@mastersthesis{gratl17task,
  address      = {Garching},
  author       = {Gratl, Fabio Alexander},
  institution  = {Institut für Informatik 5, Technische Universität München},
  month        = nov,
  organization = {Institut für Informatik 5, Technische Universität München},
  school       = {Institut für Informatik 5, Technische Universität München},
  title        = {Task Based Parallelization of the Fast Multipole Method implementation of ls1-mardyn via QuickSched},
  type         = {Master's thesis},
  year         = {2017},
  url          = {https://www5.in.tum.de/pub/Gratl_MA_TaskBasedFMM.pdf}
}

@article{CROCKETT20062809,
  title    = {On constructing a fuzzy inference framework using crisp decision trees},
  journal  = {Fuzzy Sets and Systems},
  volume   = {157},
  number   = {21},
  pages    = {2809-2832},
  year     = {2006},
  issn     = {0165-0114},
  doi      = {https://doi.org/10.1016/j.fss.2006.06.002},
  url      = {https://www.sciencedirect.com/science/article/pii/S0165011406002533},
  author   = {Keeley Crockett and Zuhair Bandar and David Mclean and James O’Shea},
  keywords = {Fuzzy inference systems, Decision trees, Genetic algorithms},
  abstract = {This paper proposes a framework which consists of a novel fuzzy inference algorithm to generate fuzzy decision trees from induced crisp decision trees. Fuzzy theoretical techniques are used to fuzzify crisp decision trees in order to soften sharp decision boundaries at decision nodes inherent in this type of trees. A framework for the investigation of various types of membership functions and fuzzy inference techniques is proposed. Once the decision tree has been fuzzified, all branches throughout the tree will fire, resulting in a membership grade being generated at each branch. Five different fuzzy inference mechanisms are used to investigate the degree of interaction between membership grades on each path in the decision tree, which ultimately leads to a final crisp classification. A genetic algorithm is used to optimize and automatically determine the set of fuzzy regions for all branches and simultaneously the degree in which the inference parameters will be applied. Comparisons between crisp trees and the fuzzified trees suggest that the later fuzzy tree is significantly more robust and produces a more balanced classification. In addition, the results obtained from five real-world data sets show that there is a significant improvement in the accuracy of the fuzzy trees when compared with crisp trees.}
}

@book{10.5555/2380985,
  author    = {Murphy, Kevin P.},
  title     = {Machine Learning: A Probabilistic Perspective},
  year      = {2012},
  isbn      = {0262018020},
  publisher = {The MIT Press},
  abstract  = {Today's Web-enabled deluge of electronic data calls for automated methods of data analysis. Machine learning provides these, developing methods that can automatically detect patterns in data and then use the uncovered patterns to predict future data. This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach. The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package--PMTK (probabilistic modeling toolkit)--that is freely available online. The book is suitable for upper-level undergraduates with an introductory-level college math background and beginning graduate students.}
}